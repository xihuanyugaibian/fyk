看到第三章，有点难。  
感觉对实际工作和其他学习作用不大，后面有机会再看。
# 并发编程的挑战

## 上下文切换

CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。  
所以任务从保存到再加载的过程就是一次上下文切换。

多线程不一定快，当并发执行累加操作不超过百万次时，速度会比串行执行累加操作更慢。因为线程有创建和上下文切换的开销。

减少上下文切换的方法有 无锁并发编程、CAS算法、使用最少线程和协程

* 无锁并发编程：多线程竞争锁时，会引起上下文切换，当多线程处理数据时，可以用一些方法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。
* CAS算法：Java的Atomic包使用CAS算法来更新数据，而不需要加锁。
* 使用最少线程：避免创建不需要的线程，如果任务少，没必要创建很多线程来处理。
* 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

## 死锁

死锁一旦发生，很难人为干预，在设计时，尽量避免。

1. 避免一个线程同时获取多个锁。
2. 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
3. 尝试使用定时锁，使用lock.tryLock(timeOut)来替代使用内部锁机制。
4. 对于数据库锁，加锁和解锁必须在同一个数据库连接里，否则会出现锁失败的情况。

## 资源限制的挑战

资源限制是指在并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。  
在并发编程中，讲代码执行速度加快的原则是将代码中串行执行的部分编程并发执行，但是如果将其某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这是程序的执行反而更慢，因为增加了上下文切换和资源调度的时间。

# Java并发机制的底层实现原理

## volatile的应用

volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的可见性。可见性是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。  
如果volatile变量修饰符使用恰当的话，它比使用synchronized的使用和执行成本更低，因为它不会引起上下文切换和调度。

volatile修饰的共享变量进行下操作的时候会多出汇编代码 `lock addl $0x0,(%esp)`。  
lock前缀的指令在多核处理器下会引发两件事情

1. 将当前处理器缓存行的数据写回系统内存（处理器通过[总线锁或缓存锁](#原子操作的实现原理)来保证该原子操作）。
2. 这个写回内存的操作会使其他CPU里缓存了该内存地址的数据无效。

## synchronized的实现原理与应用

monitorenter指令是在编译后插入同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证monitorecter必须有对应的monitorexit与之配对。  
**任何一个对象都有一个monitor与之关联，当且仅当一个monitor被持有后，它将处于锁定状态。** 线程执行到monitorehter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

### Java对象头

synchronized用的锁是存在Java的对象头里的。如果对象是数组，则虚拟机用3个字宽存储对象头，如果对象是非数组类型，则用2个字宽存储对象头。  
在32位虚拟机中，1字宽=4字节即32bit。64位虚拟机1字宽=64bit。
MarkWord：存储对象的hashCode或锁信息
ClassMetadataAddress：存储对象数据类型的指针
ArrayLength：数组的长度（数组对象才有）

### 锁的升级与对比

Java1.6为了减少获得锁和释放锁带来的性能消耗，引入了偏向锁和轻量级锁。此时锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。  
这几种状态会随着竞争情况逐渐升级。锁可以升级但不可以降级，目的是为了提高获得锁和释放锁的效率。

偏向锁：大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。
当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，
只需要简单测试一下对象头的MarkWord里是否存储着指向当前线程的偏向锁。  
如果测试成功，表示线程已经获得了锁。如果测试失败，则需要测试一下MarkWord中偏向锁标识是否设置为1（当前是偏向锁），如果不是，即无锁状态，使用CAS竞争锁；是则尝试使用CAS设置对象头的偏向锁指向当前线程。

轻量级锁：线程在执行同步块之前，JVM会先在当前线程的栈帧中创建用于存储锁记录的空间，并将对象头中的MarkWord复制到锁记录中，官方称DisplacedMarkWord。
然后线程尝试使用CAS将对象头中的MarkWord替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程尝试使用自旋来获取。  
轻量级解锁时，会使用原子的CAS操作将DisplacedMarkWord替换到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。  
因为自然会消耗CPU，为了避免无用的自旋，一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。此时
其他线程试图获取锁时，都会被阻塞住，持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁。

| 锁    | 优点                               | 缺点                       | 使用场景              |
|------|----------------------------------|--------------------------|-------------------|
| 偏向锁  | 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级差距 | 如果线程间存在锁竞争，会带来额外的锁撤销消耗   | 只有一个线程访问的同步块      |
| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度             | 如果始终得不到锁竞争的线程，使用自旋会消耗CPU | 追求响应时间，同步块执行速度非常快 |
| 重量级锁 | 线程竞争不适用自旋，不会消耗CPU                | 线程阻塞，响应时间缓慢              | 追求吞吐量，同步块执行速度较长   |

## 原子操作的实现原理

| 术语名称   | 英文                     | 解释                                                                                     |
|--------|------------------------|----------------------------------------------------------------------------------------|
| 缓存行    | Cache line             | 缓存的最小操作单位                                                                              |
| 比较并交换  | Compare and Swap       | CAS操作需要输入两个数值，一个旧值和一个新值，再操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换新值，发生了变化则不交换                     |
| CPU流水线 | CPU pipeline           | CPU流水线的工作方式就像工业生产上的装配流水线，在CPU中由5-6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5-6步后再由这些电路单元分别执行。 |
| 内存顺序冲突 | Memory order violation | 一般是由假共享引起的，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这种内存冲突时，CPU必须清空流水线              |

### 处理器如何实现原子操作

首先处理器会自动保证基本的内存操作的原子性，Pentium和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64为的操作是原子的，
但是复杂的比如跨总线宽度、跨多个缓存行和跨页表的访问处理器是不能保证其原子性的。  
但是处理器提供了总线锁定和缓存锁定两个机制来保证复杂的内存操作。

* 总线锁：使用处理器提供的一个LOCK # 信号，当一个处理器在总线上输出信号时，其他处理器的请求将被阻塞住，该处理器可以独占共享内存。
* 缓存锁：在同一时刻，我们只需要保证对某个内存地址的操作是原子性即可，但总线锁把CPU和内存之间的通信锁住了，这期间其他处理器不能操作其他内存地址的数据，开销太大。在某些场合下使用缓存锁来优化。
  频繁使用的内存会缓存在处理器的L1、L2、L3高速缓存里，原子操作就可以直接在处理器的内部缓存中进行，并不需要声明总线锁。  
  缓存锁定是指内存区域如果被缓存在处理器的缓存中，并且在Lock操作期间被锁定，那么当他执行锁操作回写到内存时，处理器不在总线上声言
  LOCK #信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，
  因为缓存一致性机制会阻止同时修改两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。

两种情况不会使用缓存行

1. 操作的数据不崩被缓存在处理器内部或操作的数据跨多个缓存行时，则处理器会调用总线锁定。
2. 有些处理器不支持缓存行锁定 例如Intel 486。

针对不能使用缓存行 Intel处理器提供了很多Lock前缀的指令来实现。  
位测试和修改指令：BTS BTR BTC，交换指令：XADD CMPXCHG，操作数和逻辑指令 ADD OR ，被这些指令操作的内存区域会加锁，导致其他处理器不能同时访问它。

### Java如何实现原子操作

在Java中通过锁和循环CAS操作来实现原子操作。

JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。  
CAS实现原子操作有三个问题

1. ABA问题：解决思路是使用版本号，A-B-A 变成1A-2B-3A
2. 循环时间长开销大：自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。
3. 只能保证一个共享变量的原子操作：对多个变量进行操作时，循环CAS无法保证操作的原子性，此时可以用锁，也可以把索格共享变量合并成一个共享变量。

# Java内存模型

## Java内存模型的基础

### 并发编程模型的两个关键问题

在并发编程中需要处理两个关键问题：线程之间如何通信和线程之间如何同步。

* 通信指线程之间以何种机制来交换信息。有共享内存和消息传递
  * 在共享内存并发模型里：线程之间共享程序的公共状态，通过读写内存中公共状态进行隐式通信。
  * 在消息传递并发模型里：线程之间没有公共状态，线程之间必须通过发送消息来显示进行通信。
* 同步指程序中用于控制不同线程间操作发生相对顺序的机制。
  * 在共享内存并发模型里：同步是显示进行的，程序员必须显示指定某个方法或某段代码需要在线程之间互斥执行。
  * 在消息传递并发模型里：由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。

Java采用的是共享内存模型，通信是隐式的，同步是显式的。

### Java内存模型的抽象结构

Java线程之间的通信由**Java内存模型（JMM）**控制，JMM决定了一个线程对共享变量的写入何时对另一个线程可见。

从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。  
本地内存是JMM的一个抽象概念，并不真是存在，它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。

### 从源代码到指令重排序

执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。

1. 编译器优化的重排序
2. 指令级并行的重排序
3. 内存系统的重排序

为了保证内存可见性，Java编译器在生成指令序列的合适位置会插入内存屏障来禁止特定类型的处理器重排序。

### happens-before

在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。

* 程序顺序规则：一个线程中的每个操作，happens-before与该线程中的任意后续操作。
* 监视器锁规则：对一个锁的解锁，happens-before与对这个锁的加锁。
* volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
* 传递性：如果 A happens-before B，且 B happens-before C，那么 A happens-before C.

两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行，仅仅要求前一个操作执行的结果对后一个操作可见，且前一个操作按顺序排在第二个操作之前。

## 重排序

* 编译器和处理器在重排序是，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。（仅针对单个处理器中执行的指令序列和单个线程中执行的操作）
* as-if-serial：不管怎么排序，点线程程序的执行结果不能被改变。
* 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的结果。

## 顺序一致性
